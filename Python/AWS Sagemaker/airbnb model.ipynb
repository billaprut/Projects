{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.session import s3_input, Session\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an s3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'appplication' # CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "my_region = boto3.session.Session().region_name  # set the region of the instance\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if my_region == 'us-east-1':\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    print('S3 bucket created successfully')\n",
    "except:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping the path of the models in s3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://appplication/xgboost-as-a-built-in-algo/output\n"
     ]
    }
   ],
   "source": [
    "# set an output path where the trained model will be saved\n",
    "prefix = 'xgboost-as-a-built-in-algo'\n",
    "output_path = 's3://{}/{}/output'.format(bucket_name, prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>high_booking_rate</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>extra_people</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cathy's Cozy Cottage</td>\n",
       "      <td>2</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$75.00</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>100%</td>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private Entrance! Bay View! Quiet!</td>\n",
       "      <td>2</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>$50.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>$99.00</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>92%</td>\n",
       "      <td>False</td>\n",
       "      <td>100%</td>\n",
       "      <td>1</td>\n",
       "      <td>San Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beautiful Bohemian Getaway</td>\n",
       "      <td>5</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>$15.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$75.00</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$12.00</td>\n",
       "      <td>97%</td>\n",
       "      <td>False</td>\n",
       "      <td>69%</td>\n",
       "      <td>1</td>\n",
       "      <td>San Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lux Wash Park Home Gr8 4 families</td>\n",
       "      <td>10</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>strict</td>\n",
       "      <td>$100.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$411.00</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>$50.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>100%</td>\n",
       "      <td>3</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huge private bedroom with park views</td>\n",
       "      <td>2</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$75.00</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>100%</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  accommodates  bed_type  bedrooms  \\\n",
       "0                  Cathy's Cozy Cottage             2  Real Bed       1.0   \n",
       "1    Private Entrance! Bay View! Quiet!             2  Real Bed       1.0   \n",
       "2            Beautiful Bohemian Getaway             5  Real Bed       1.0   \n",
       "3     Lux Wash Park Home Gr8 4 families            10  Real Bed       5.0   \n",
       "4  Huge private bedroom with park views             2  Real Bed       1.0   \n",
       "\n",
       "   beds cancellation_policy cleaning_fee  host_total_listings_count    price  \\\n",
       "0   1.0            moderate          NaN                        1.0   $75.00   \n",
       "1   2.0            moderate       $50.00                        2.0   $99.00   \n",
       "2   3.0            moderate       $15.00                        1.0   $75.00   \n",
       "3   8.0              strict      $100.00                        1.0  $411.00   \n",
       "4   1.0            moderate          NaN                        1.0   $75.00   \n",
       "\n",
       "  property_type        room_type  high_booking_rate  bathrooms extra_people  \\\n",
       "0         House     Private room                  1        1.0        $0.00   \n",
       "1         House     Private room                  0        1.0        $0.00   \n",
       "2   Condominium     Private room                  1        1.0       $12.00   \n",
       "3         House  Entire home/apt                  0        4.0       $50.00   \n",
       "4     Apartment     Private room                  0        1.0        $0.00   \n",
       "\n",
       "  host_acceptance_rate host_is_superhost host_response_rate  minimum_nights  \\\n",
       "0                  NaN             False               100%               2   \n",
       "1                  92%             False               100%               1   \n",
       "2                  97%             False                69%               1   \n",
       "3                  NaN             False               100%               3   \n",
       "4                  NaN             False               100%               1   \n",
       "\n",
       "        market  \n",
       "0  Los Angeles  \n",
       "1    San Diego  \n",
       "2    San Diego  \n",
       "3       Denver  \n",
       "4     New York  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('airbnb_hw2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValueHandler:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def report_missing_values(self):\n",
    "        mis_val = self.df.isnull().sum()\n",
    "        mis_val_pct = 100 * mis_val / len(self.df)\n",
    "        mis_val_tab = pd.concat([mis_val, mis_val_pct], axis=1)\n",
    "        mis_val_tab_renamed = mis_val_tab.rename(columns={0: 'Missing Values', 1: '% of Total Values'})\n",
    "        mis_val_tab_renamed = mis_val_tab_renamed[mis_val_tab_renamed.iloc[:, 1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n",
    "        print(f\"Your selected dataframe has {self.df.shape[1]} columns.\\nThere are {mis_val_tab_renamed.shape[0]} columns that have missing values.\")\n",
    "        return mis_val_tab_renamed\n",
    "\n",
    "    def fill_with_value(self, columns, value):\n",
    "        if isinstance(columns, list):\n",
    "            for col in columns:\n",
    "                self.df[col].fillna(value, inplace=True)\n",
    "        else:\n",
    "            self.df[columns].fillna(value, inplace=True)\n",
    "\n",
    "    def fill_forward(self, columns):\n",
    "        if isinstance(columns, list):\n",
    "            for col in columns:\n",
    "                self.df[col].fillna(method='ffill', inplace=True)\n",
    "        else:\n",
    "            self.df[columns].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    def fill_backward(self, columns):\n",
    "        if isinstance(columns, list):\n",
    "            for col in columns:\n",
    "                self.df[col].fillna(method='bfill', inplace=True)\n",
    "        else:\n",
    "            self.df[columns].fillna(method='bfill', inplace=True)\n",
    "\n",
    "    def fill_with_mean(self, columns):\n",
    "        if isinstance(columns, list):\n",
    "            for col in columns:\n",
    "                self.df[col].fillna(self.df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            self.df[columns].fillna(self.df[columns].mean(), inplace=True)\n",
    "\n",
    "    def fill_with_median(self, columns):\n",
    "        if isinstance(columns, list):\n",
    "            for col in columns:\n",
    "                self.df[col].fillna(self.df[col].median(), inplace=True)\n",
    "        else:\n",
    "            self.df[columns].fillna(self.df[columns].median(), inplace=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 19 columns.\n",
      "There are 10 columns that have missing values.\n",
      "                           Missing Values  % of Total Values\n",
      "host_acceptance_rate                 9216               92.2\n",
      "cleaning_fee                         1839               18.4\n",
      "host_response_rate                   1662               16.6\n",
      "market                                 33                0.3\n",
      "bathrooms                              31                0.3\n",
      "host_total_listings_count              19                0.2\n",
      "host_is_superhost                      19                0.2\n",
      "beds                                   12                0.1\n",
      "bedrooms                                9                0.1\n",
      "name                                    1                0.0\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the class:\n",
    "handler = MissingValueHandler(df)\n",
    "\n",
    "missing_report = handler.report_missing_values()\n",
    "print(missing_report)\n",
    "\n",
    "\n",
    "# Code \n",
    "\n",
    "handler.fill_with_value(['cleaning_fee'], 0)\n",
    "handler.fill_with_mean(['bedrooms', 'beds', 'host_total_listings_count'])\n",
    "handler.fill_with_value(['name'], 'Missing')\n",
    "\n",
    "# Replace NAs in bathrooms with the median value\n",
    "handler.fill_with_median('bathrooms')\n",
    "\n",
    "# Replace NAs in host_is_superhost with False\n",
    "df['host_is_superhost'].fillna(False, inplace=True)\n",
    "\n",
    "# Group \"strict\" and \"super_strict_30\" into \"strict\" in cancellation_policy\n",
    "df['cancellation_policy'] = df['cancellation_policy'].replace('super_strict_30', 'strict')\n",
    "\n",
    "# Convert cleaning_fee and price into numbers and replace NAs with 0\n",
    "df['cleaning_fee'] = pd.to_numeric(df['cleaning_fee'].str.replace('[\\$,]', '', regex=True), errors='coerce').fillna(0)\n",
    "df['price'] = pd.to_numeric(df['price'].str.replace('[\\$,]', '', regex=True), errors='coerce').fillna(0)\n",
    "\n",
    "# Convert extra_people into numbers\n",
    "df['extra_people'] = df['extra_people'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Create new variables\n",
    "df['charges_for_extra'] = np.where(df['extra_people'] > 0, 'YES', 'NO')\n",
    "df['host_acceptance'] = np.where(df['host_acceptance_rate'].isna(), 'MISSING', \n",
    "                                     np.where(df['host_acceptance_rate'] == '100%', 'ALL', 'SOME'))\n",
    "df['host_response'] = np.where(df['host_response_rate'].isna(), 'MISSING', \n",
    "                                    np.where(df['host_response_rate'] == '100%', 'ALL', 'SOME'))\n",
    "df['has_min_nights'] = np.where(df['minimum_nights'] > 1, 'YES', 'NO')\n",
    "\n",
    "# Count the number of instances in each market\n",
    "market_counts = df['market'].value_counts()\n",
    "\n",
    "# Identify markets with under 300 instances\n",
    "under_300_markets = market_counts[market_counts < 300].index.tolist()\n",
    "\n",
    "# Replace under 300 markets with \"OTHER\"\n",
    "df.loc[df['market'].isin(under_300_markets), 'market'] = 'OTHER'\n",
    "\n",
    "# Replace NAs in market\n",
    "df['market'].fillna('OTHER', inplace=True)\n",
    "\n",
    "\n",
    "# Creating some new variables\n",
    "\n",
    "# price_per_person\n",
    "df['price_per_person'] = df['price'] / df['accommodates']\n",
    "\n",
    "# has_cleaning_fee\n",
    "df['has_cleaning_fee'] = df['cleaning_fee'].apply(lambda x: 'YES' if x > 0 else 'NO')\n",
    "\n",
    "# bed_category\n",
    "df['bed_category'] = df['bed_type'].apply(lambda x: 'bed' if x == 'Real Bed' else 'other')\n",
    "\n",
    "# property_category\n",
    "property_categories = {\n",
    "    'Apartment': 'apartment', 'Serviced apartment': 'apartment', 'Loft': 'apartment',\n",
    "    'Bed & Breakfast': 'hotel', 'Boutique hotel': 'hotel', 'Hostel': 'hotel',\n",
    "    'Townhouse': 'condo', 'Condominium': 'condo',\n",
    "    'Bungalow': 'house', 'House': 'house'\n",
    "}\n",
    "df['property_category'] = df['property_type'].map(property_categories).fillna('other')\n",
    "\n",
    "# Convert property_category to a factor (category in pandas)\n",
    "#df['property_category'] = df['property_category'].astype('category')\n",
    "\n",
    "# ppp_ind\n",
    "median_ppp = df.groupby('property_category')['price_per_person'].transform('median')\n",
    "df['ppp_ind'] = (df['price_per_person'] > median_ppp).astype(int)\n",
    "\n",
    "# Convert market to a categorical variable\n",
    "df['market'] = df['market'].astype('category')\n",
    "\n",
    "# Convert high_booking_rate to a categorical variable\n",
    "df['high_booking_rate'] = df['high_booking_rate'].astype('category')\n",
    "\n",
    "\n",
    "# This cell contains all dataframes needed for predictive analytics\n",
    "\n",
    "# Selecting features and target\n",
    "df = df[[\"accommodates\", \"bedrooms\", \"beds\", \"high_booking_rate\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker XGBoost can train on data in either a CSV or LibSVM format. It should have the following:\n",
    "\n",
    "- Have the target variable in the first column\n",
    "- Not have a header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high_booking_rate</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     high_booking_rate  accommodates  bedrooms  beds\n",
       "0                    1             2       1.0   1.0\n",
       "1                    0             2       1.0   2.0\n",
       "2                    1             5       1.0   3.0\n",
       "3                    0            10       5.0   8.0\n",
       "4                    0             2       1.0   1.0\n",
       "...                ...           ...       ...   ...\n",
       "9995                 0             2       0.0   1.0\n",
       "9996                 0             4       1.0   2.0\n",
       "9997                 0             8       4.0   4.0\n",
       "9998                 0             4       1.0   2.0\n",
       "9999                 0             4       2.0   3.0\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df['high_booking_rate'], df.drop(['high_booking_rate'], axis=1)], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = np.split(df.sample(frac=1, random_state=1729), [int(0.7 * len(df))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "test_data.to_csv('test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "### Saving Train and Test Into Buckets\n",
    "## We start with Train Data\n",
    "import os\n",
    "#pd.concat([train_data['high_booking_rate'], train_data.drop(['high_booking_rate'], axis = 1)], axis = 1).to_csv('train.csv', index = False, header = False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type= 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "# Test Data Into Buckets\n",
    "#pd.concat([test_data['high_booking_rate'], test_data.drop(['high_booking_rate'], axis = 1)], axis = 1).to_csv('test.csv', index = False, header = False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "s3_input_test = sagemaker.TrainingInput(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type= 'csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Models Xgboost- Inbuilt Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"verbosity\":\"1\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"50\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.7-1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.2xlarge', \n",
    "                                          volume_size=5, # 5 GB \n",
    "                                          output_path=output_path,\n",
    "                                          use_spot_instances=True,\n",
    "                                          max_run = 300,\n",
    "                                          max_wait = 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2024-01-31-04-23-11-828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 04:23:11 Starting - Starting the training job...\n",
      "2024-01-31 04:23:27 Starting - Preparing the instances for training......\n",
      "2024-01-31 04:24:34 Downloading - Downloading input data...\n",
      "2024-01-31 04:24:59 Downloading - Downloading the training image......\n",
      "2024-01-31 04:26:10 Training - Training image download completed. Training in progress....\n",
      "2024-01-31 04:26:35 Uploading - Uploading generated training model\u001b[34m[2024-01-31 04:26:29.756 ip-10-2-82-224.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-01-31 04:26:29.779 ip-10-2-82-224.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] File path /opt/ml/input/data/train of input files\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Making smlinks from folder /opt/ml/input/data/train to folder /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] creating symlink between Path /opt/ml/input/data/train/train.csv and destination /tmp/sagemaker_xgboost_input_data/train.csv-3183237270582464426\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] files path: /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] File path /opt/ml/input/data/validation of input files\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Making smlinks from folder /opt/ml/input/data/validation to folder /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] creating symlink between Path /opt/ml/input/data/validation/test.csv and destination /tmp/sagemaker_xgboost_input_data/test.csv6429974040072890474\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] files path: /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Train matrix has 7000 rows and 3 columns\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Validation matrix has 3000 rows\u001b[0m\n",
      "\u001b[34m[2024-01-31 04:26:30.222 ip-10-2-82-224.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-01-31 04:26:30.222 ip-10-2-82-224.ec2.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-01-31 04:26:30.223 ip-10-2-82-224.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-01-31 04:26:30.223 ip-10-2-82-224.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-01-31:04:26:30:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[0]#011train-logloss:0.64488#011validation-logloss:0.64206\u001b[0m\n",
      "\u001b[34m[2024-01-31 04:26:30.229 ip-10-2-82-224.ec2.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2024-01-31 04:26:30.231 ip-10-2-82-224.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-logloss:0.61306#011validation-logloss:0.60807\u001b[0m\n",
      "\u001b[34m[2]#011train-logloss:0.59158#011validation-logloss:0.58467\u001b[0m\n",
      "\u001b[34m[3]#011train-logloss:0.57666#011validation-logloss:0.56820\u001b[0m\n",
      "\u001b[34m[4]#011train-logloss:0.56690#011validation-logloss:0.55766\u001b[0m\n",
      "\u001b[34m[5]#011train-logloss:0.56043#011validation-logloss:0.55001\u001b[0m\n",
      "\u001b[34m[6]#011train-logloss:0.55574#011validation-logloss:0.54463\u001b[0m\n",
      "\u001b[34m[7]#011train-logloss:0.55274#011validation-logloss:0.54081\u001b[0m\n",
      "\u001b[34m[8]#011train-logloss:0.55044#011validation-logloss:0.53842\u001b[0m\n",
      "\u001b[34m[9]#011train-logloss:0.54895#011validation-logloss:0.53645\u001b[0m\n",
      "\u001b[34m[10]#011train-logloss:0.54770#011validation-logloss:0.53539\u001b[0m\n",
      "\u001b[34m[11]#011train-logloss:0.54722#011validation-logloss:0.53450\u001b[0m\n",
      "\u001b[34m[12]#011train-logloss:0.54699#011validation-logloss:0.53402\u001b[0m\n",
      "\u001b[34m[13]#011train-logloss:0.54690#011validation-logloss:0.53381\u001b[0m\n",
      "\u001b[34m[14]#011train-logloss:0.54671#011validation-logloss:0.53333\u001b[0m\n",
      "\u001b[34m[15]#011train-logloss:0.54632#011validation-logloss:0.53299\u001b[0m\n",
      "\u001b[34m[16]#011train-logloss:0.54588#011validation-logloss:0.53264\u001b[0m\n",
      "\u001b[34m[17]#011train-logloss:0.54571#011validation-logloss:0.53261\u001b[0m\n",
      "\u001b[34m[18]#011train-logloss:0.54556#011validation-logloss:0.53244\u001b[0m\n",
      "\u001b[34m[19]#011train-logloss:0.54537#011validation-logloss:0.53258\u001b[0m\n",
      "\u001b[34m[20]#011train-logloss:0.54493#011validation-logloss:0.53253\u001b[0m\n",
      "\u001b[34m[21]#011train-logloss:0.54493#011validation-logloss:0.53246\u001b[0m\n",
      "\u001b[34m[22]#011train-logloss:0.54487#011validation-logloss:0.53267\u001b[0m\n",
      "\u001b[34m[23]#011train-logloss:0.54463#011validation-logloss:0.53284\u001b[0m\n",
      "\u001b[34m[24]#011train-logloss:0.54463#011validation-logloss:0.53278\u001b[0m\n",
      "\u001b[34m[25]#011train-logloss:0.54455#011validation-logloss:0.53258\u001b[0m\n",
      "\u001b[34m[26]#011train-logloss:0.54454#011validation-logloss:0.53255\u001b[0m\n",
      "\u001b[34m[27]#011train-logloss:0.54454#011validation-logloss:0.53251\u001b[0m\n",
      "\u001b[34m[28]#011train-logloss:0.54455#011validation-logloss:0.53258\u001b[0m\n",
      "\u001b[34m[29]#011train-logloss:0.54455#011validation-logloss:0.53262\u001b[0m\n",
      "\u001b[34m[30]#011train-logloss:0.54455#011validation-logloss:0.53258\u001b[0m\n",
      "\u001b[34m[31]#011train-logloss:0.54455#011validation-logloss:0.53265\u001b[0m\n",
      "\u001b[34m[32]#011train-logloss:0.54446#011validation-logloss:0.53252\u001b[0m\n",
      "\u001b[34m[33]#011train-logloss:0.54446#011validation-logloss:0.53258\u001b[0m\n",
      "\u001b[34m[34]#011train-logloss:0.54438#011validation-logloss:0.53237\u001b[0m\n",
      "\u001b[34m[35]#011train-logloss:0.54438#011validation-logloss:0.53233\u001b[0m\n",
      "\u001b[34m[36]#011train-logloss:0.54439#011validation-logloss:0.53239\u001b[0m\n",
      "\u001b[34m[37]#011train-logloss:0.54422#011validation-logloss:0.53253\u001b[0m\n",
      "\u001b[34m[38]#011train-logloss:0.54421#011validation-logloss:0.53249\u001b[0m\n",
      "\u001b[34m[39]#011train-logloss:0.54421#011validation-logloss:0.53250\u001b[0m\n",
      "\u001b[34m[40]#011train-logloss:0.54421#011validation-logloss:0.53247\u001b[0m\n",
      "\u001b[34m[41]#011train-logloss:0.54421#011validation-logloss:0.53245\u001b[0m\n",
      "\u001b[34m[42]#011train-logloss:0.54421#011validation-logloss:0.53239\u001b[0m\n",
      "\u001b[34m[43]#011train-logloss:0.54421#011validation-logloss:0.53250\u001b[0m\n",
      "\u001b[34m[44]#011train-logloss:0.54421#011validation-logloss:0.53251\u001b[0m\n",
      "\u001b[34m[45]#011train-logloss:0.54393#011validation-logloss:0.53274\u001b[0m\n",
      "\u001b[34m[46]#011train-logloss:0.54393#011validation-logloss:0.53274\u001b[0m\n",
      "\u001b[34m[47]#011train-logloss:0.54383#011validation-logloss:0.53263\u001b[0m\n",
      "\u001b[34m[48]#011train-logloss:0.54384#011validation-logloss:0.53254\u001b[0m\n",
      "\u001b[34m[49]#011train-logloss:0.54385#011validation-logloss:0.53246\u001b[0m\n",
      "\n",
      "2024-01-31 04:26:46 Completed - Training job completed\n",
      "Training seconds: 132\n",
      "Billable seconds: 61\n",
      "Managed Spot Training savings: 53.8%\n"
     ]
    }
   ],
   "source": [
    "# execute the XGBoost training job\n",
    "estimator.fit({'train': s3_input_train, 'validation': s3_input_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy ML model as Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-01-31-04-28-04-742\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2024-01-31-04-28-04-742\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2024-01-31-04-28-04-742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = estimator.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.m4.xlarge',\n",
    "    serializer = CSVSerializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = []\n",
    "    for array in split_array:\n",
    "        result = xgb_predictor.predict(array).decode('utf-8')\n",
    "        # Splitting by newline and then by commas\n",
    "        for line in result.strip().split('\\n'):\n",
    "            predictions.extend(line.split(','))\n",
    "\n",
    "    return np.array(predictions, dtype=float)\n",
    "\n",
    "predictions = predict(test_data.to_numpy()[:,1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate: 76.8%\n",
      "\n",
      "Predicted      Not High           High\n",
      "Observed\n",
      "Not High       77% (2296)    36% (4)\n",
      "High            23% (693)     64% (7) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = pd.crosstab(index=test_data['high_booking_rate'], \n",
    "columns=np.round(predictions), \n",
    "rownames=['Observed'], colnames=['Predicted']) \n",
    "tn = cm.iloc[0, 0] \n",
    "fn = cm.iloc[1, 0] \n",
    "tp = cm.iloc[1, 1] \n",
    "fp = cm.iloc[0, 1] \n",
    "p = (tp + tn) / (tp + tn + fp + fn) * 100 \n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p)) \n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"Not High\", \"High\")) \n",
    "print(\"Observed\") \n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"Not High\", tn / (tn + fn) * 100, tn, fp / (tp + fp) * 100, fp)) \n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"High\", fn / (tn + fn) * 100, fn, tp / (tp + fp) * 100, tp)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting the Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: sagemaker-xgboost-2024-01-31-04-28-04-742\n",
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-xgboost-2024-01-31-04-28-04-742\n"
     ]
    }
   ],
   "source": [
    "xgb_predictor.delete_endpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'ZKG0K8CD2G92YQAE',\n",
       "   'HostId': 'z1lPYQuIx00GiCqzJoRti5iSxX0n1Xje1zbKTczyWfIEklg5SG40/kNM7re/omz0iLvxodVmCLo=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'z1lPYQuIx00GiCqzJoRti5iSxX0n1Xje1zbKTczyWfIEklg5SG40/kNM7re/omz0iLvxodVmCLo=',\n",
       "    'x-amz-request-id': 'ZKG0K8CD2G92YQAE',\n",
       "    'date': 'Wed, 31 Jan 2024 04:54:48 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/profiler-output/system/incremental/2024013103/1706672040.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/output/model.tar.gz'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/events/000000000010/000000000010_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/test/test.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/index/000000000/000000000010_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/index/000000000/000000000000_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/index/000000000/000000000020_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/profiler-output/system/incremental/2024013103/1706670180.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/events/000000000010/000000000010_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/index/000000000/000000000040_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/index/000000000/000000000030_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/events/000000000040/000000000040_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/profiler-output/system/incremental/2024013103/1706672100.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/index/000000000/000000000020_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/events/000000000020/000000000020_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/profiler-output/system/incremental/2024013104/1706675160.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/index/000000000/000000000010_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/output/model.tar.gz'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/index/000000000/000000000010_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/profiler-output/system/incremental/2024013103/1706670240.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/profiler-output/system/incremental/2024013103/1706672160.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/events/000000000040/000000000040_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/profiler-output/system/incremental/2024013104/1706675040.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/profiler-output/system/incremental/2024013103/1706670300.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/index/000000000/000000000030_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/events/000000000030/000000000030_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/events/000000000030/000000000030_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/index/000000000/000000000040_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/index/000000000/000000000000_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/index/000000000/000000000000_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/train/train.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/events/000000000020/000000000020_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/profiler-output/system/incremental/2024013104/1706675100.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/index/000000000/000000000020_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/events/000000000040/000000000040_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/claim.smd'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/events/000000000020/000000000020_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/index/000000000/000000000040_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/events/000000000030/000000000030_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-04-23-11-828/debug-output/claim.smd'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/index/000000000/000000000030_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/debug-output/claim.smd'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/output/model.tar.gz'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-02-04-573/debug-output/events/000000000010/000000000010_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-01-31-03-33-01-120/profiler-output/system/training_job_end.ts'}]}]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
